#Invert Indices 
#Shuntaro Koizumi
#240521

rm(list = ls())
setwd('~/OneDrive/NORCE LFI/Indeksutregning/Invert Data')
#devtools::install("C:/Users/shunk/OneDrive/Documents/OneDrive/NORCE LFI/naiad package")

library(data.table)
library(tidyr)
library(stringr)
library(lubridate)
library(dplyr)
library(stringi)
library(readxl)

flom2023 <- read.csv('Flomsikring 2023_edit.csv')
dale2023 <- read.csv('dale2023_edit.csv')

flom2023 <- melt(setDT(flom2023), id.vars = c('var','taxa'),variable.name = 'station')
dale2023 <- melt(setDT(dale2023), id.vars = c('var','taxa'),variable.name = 'station')

#Data Cleaning - Flom Dataset
flom2023 <- flom2023[! is.na(flom2023$value),] 

names(flom2023)[names(flom2023) == 'taxa'] <- 'Species'
names(flom2023)[names(flom2023) == 'value'] <- 'Value'
names(flom2023)[names(flom2023) == 'station'] <- 'Station'

flom2023 <- separate(flom2023, Station,sep = '_',c('River','Date','Station','trt'))
flom2023$Date <- dmy(flom2023$Date)

flom2023$id <-  paste(flom2023$River,flom2023$Date,flom2023$Station, sep = '_')

#Data Cleaning - Dale Dataset
dale2023 <- dale2023[! is.na(dale2023$value),] 

names(dale2023)[names(dale2023) == 'taxa'] <- 'Species'
names(dale2023)[names(dale2023) == 'value'] <- 'Value'
names(dale2023)[names(dale2023) == 'station'] <- 'Station'

dale2023 <- separate(dale2023, Station,sep = '_',c('River','Station','Date','trt'))
dale2023$Date <- ymd(dale2023$Date)

dale2023$id <-  paste(dale2023$River,dale2023$Date,dale2023$Station, sep = '_')

#Ordination and permANOVA
library(naiad)

cleanTax(flom2023)
p1_2023 <- dataClean

cleanTax(dale2023)
p2_2023 <- dataClean

comp2023 <- rbind(p1_2023,p2_2023)
#Flom Ordinations
flomwide <- spread(comp2023, key = Species, value = Value)
flomwide[is.na(flomwide)] = 0

flomwide <- flomwide %>%
  rowwise() %>%
  mutate(sum = rowSums(across(where(is.numeric)), na.rm=TRUE))

#flomwidetest <- flomwide[sample(1:nrow(flomwide)), ]
#flomwide <- flomwide[!flomwide$`Pisidium sp.`,]
library(vegan)
flomspec <- flomwide %>% 
  select(Acari:Tipula)
env = flomwide %>% 
  select(River,Station,trt,Date)

env$row <- 1:nrow(env)
env$cluster <-  1
env$cluster[(env$row > 20 & env$row <= 24)] = 2
env$cluster[(env$row > 24 & env$row <= 42)] = 3
env$cluster[(env$row > 42 & env$row <= 62)] = 4

#flomspec <- log1p(flomspec)

min_occurrences <- 2
flomspec <- flomspec[, colSums(flomspec > 0) >= min_occurrences]

#min_abundance <- 5http://127.0.0.1:14481/graphics/plot_zoom_png?width=1904&height=970
#flomspec <- flomspec[, colSums(flomspec) >= min_abundance]

env$trt <- as.factor(env$trt)
nmdsflom = metaMDS(flomspec,distance="bray",k = 9,maxtry=1000)
nmdsflom
plot(nmdsflom)
col_vec <- c("lightgrey", "darkgreen", "darkblue","darkorange")
disp <- "sites"
#scl <- "symmetric"
ordiellipse(nmdsflom, groups = env$cluster,
            kind = "ehull", col = col_vec, lwd = 2)
## standard error of centroid  ellipse
ordiellipse(nmdsflom, groups = env$cluster,
            draw = "polygon", col = col_vec,lwd = 2)
ordispider(nmdsflom, groups = env$cluster,
           col = col_vec,label = FALSE)

points(nmdsflom, display = disp,groups = env$trt,
       pch = 21, col = c("red","black"), bg = c("red","black"))
#text(nmdsflom$species,labels=substr(rownames(nmdsflom$species),1,15),cex=0.7,col='#547d4c')

text(nmdsflom, display="sites")

ano <- anosim(flomspec, env$trt,distance='bray',permutations = 9999)
ano

#Separate out the environmental data and fit it to the nmds 

#envfit_result <- envfit(nmdsflom ~ trt + cluster + River + Station,  data = env)
#envfit_result
#pcoflom <- wcmdscale(vegdist(flomspec), eig = TRUE, add = 'cailliez')
#plot(pcoflom)
#scrs <- scores(pcoflom, choices = 1:2)
#spp_scrs <- wascores(scrs, flomspec,
#                     expand = FALSE)
#points(spp_scrs, col = "red", pch = 19)
#ordiellipse(pcoflom, groups = env$trt,
#            kind = "se", col = col_vec,
#            scaling = scl, lwd = 2)
## standard error of centroid  ellipse
#ordiellipse(pcoflom, groups = env$trt,
#            draw = "polygon", col = col_vec,
#            scaling = scl, lwd = 2)
#ordispider(pcoflom, groups = env$trt,
#           col = col_vec,
#           scaling = scl, label = TRUE)
#points(pcoflom, display = disp, scaling = scl,
#       pch = 21, col = "black", bg = "red")

flom_permanova <- adonis2(flomspec ~ cluster + trt + cluster:trt, data = env, permutations = 999)
flom_permanova

flom_permanova <- adonis2(flomspec ~ trt, data = env, permutations = 999)
flom_permanova

dis <- vegdist(flomspec)
groups <- env$trt

mod <-  betadisper(dis, groups)
mod

boxplot(mod)
permutest(mod, pairwise = TRUE)

env$trt <- as.factor(env$trt)

#pca <- rda(decostand(flomspec, method = 'hellinger'), scale = TRUE)
#biplot(pca)
#ordiellipse(pca, groups = env$trt,
#            kind = "ehull", col = col_vec,
#            scaling = scl, lwd = 2)
## standard error of centroid  ellipse
#ordiellipse(pca, groups = env$trt,
#            draw = "polygon", col = col_vec,
#            scaling = scl, lwd = 2)
#ordispider(pca, groups = env$trt,
#           col = col_vec,
#           scaling = scl, label = TRUE)
#points(pca, display = disp, scaling = scl,
#       pch = 21, col = "black", bg = "red")
#screeplot(pca, bstick = TRUE, type = "l",
#          main = NULL)

#library(rpart)
#library(rpart.plot)
#tree <- rpart(Value ~ Species + trt + River + Station,data = flom2023)
#prp(tree, faclen = 2)
#rpart.plot(tree,box.palette = "white")

 #NAIAD
library(naiad)

#Flom 2023
cleanTax(flom2023)

F1F2 <- f1f2(dataClean)
rami <- rami(dataClean)
aspt <- ASPT(dataClean)
tc <-  taxaCount(dataClean)
shan <- sdi(dataClean)
psi <- psi(dataClean) 

finalflom23 <- merge(F1F2,rami)
finalflom23 <- merge(finalflom23, aspt)
finalflom23 <- merge(finalflom23, tc)
finalflom23 <- merge(finalflom23, shan)
finalflom23 <- merge(finalflom23, psi)

#Elve2023 
elve2023 <- read.csv('elve2023.csv')
elve2023 <- melt(setDT(elve2023), id.vars = c('taxa','smt','river','date'),variable.name = 'Station')

names(elve2023)[names(elve2023) == 'river'] <- 'River'
names(elve2023)[names(elve2023) == 'taxa'] <- 'Species'
names(elve2023)[names(elve2023) == 'value'] <- 'Value'
names(elve2023)[names(elve2023) == 'station'] <- 'Station'
names(elve2023)[names(elve2023) == 'date'] <- 'Date'

elve2023 <- elve2023[! is.na(elve2023$Value),] 
elve2023$Date <- ymd(elve2023$Date)

cleanTax(elve2023)

F1F2 <- f1f2(dataClean)
rami <- rami(dataClean)
aspt <- ASPT(dataClean)
tc <-  taxaCount(dataClean)
shan <- sdi(dataClean)
psi <- psi(dataClean) 

finalelve23 <- merge(F1F2,rami)
finalelve23 <- merge(finalelve23, aspt)
finalelve23 <- merge(finalelve23, tc)
finalelve23 <- merge(finalelve23, shan)
finalelve23 <- merge(finalelve23, psi)

write.csv(finalelve23,'Elveovervåking 2023_Calculated.csv')

#Dale Indices
cleanTax(dale2023)

F1F2 <- f1f2(dataClean)
rami <- rami(dataClean)
aspt <- ASPT(dataClean)
tc <-  taxaCount(dataClean)
shan <- sdi(dataClean)
psi <- psi(dataClean) 

finaldale23 <- merge(F1F2,rami)
finaldale23 <- merge(finaldale23, aspt)
finaldale23 <- merge(finaldale23, tc)
finaldale23 <- merge(finaldale23, shan)
finaldale23 <- merge(finaldale23, psi)

write.csv(finaldale23,'Dale 2023_Calculated.csv')

#Elve Var 2023 
elvVar2023 <- read.csv('elveovervåkingVar 2023_edit.csv')
elvVar2023 <- melt(setDT(elvVar2023), id.vars = c('var','taxa'),variable.name = 'station')
#Data Cleaning - Flom Dataset
elvVar2023 <- elvVar2023[! is.na(elvVar2023$value),] 

names(elvVar2023)[names(elvVar2023) == 'taxa'] <- 'Species'
names(elvVar2023)[names(elvVar2023) == 'value'] <- 'Value'
names(elvVar2023)[names(elvVar2023) == 'station'] <- 'Station'

elvVar2023 <- separate(elvVar2023, Station,sep = '_',c('River','Date','Station'))
elvVar2023$Date <- ymd(elvVar2023$Date)

elvVar2023$id <-  paste(elvVar2023$River,elvVar2023$Date,elvVar2023$Station, sep = '_')

cleanTax(elvVar2023)

F1F2 <- f1f2(dataClean)
rami <- rami(dataClean)
aspt <- ASPT(dataClean)
tc <-  taxaCount(dataClean)
shan <- sdi(dataClean)
psi <- psi(dataClean) 

finalelvVar23 <- merge(F1F2,rami)
finalelvVar23 <- merge(finalelvVar23, aspt)
finalelvVar23 <- merge(finalelvVar23, tc)
finalelvVar23 <- merge(finalelvVar23, shan)
finalelvVar23 <- merge(finalelvVar23, psi)

write.csv(finalelvVar23,'elvVar 2023_Calculated.csv')
